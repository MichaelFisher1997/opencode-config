# ğŸš€ OpenCode Configuration

My personal OpenCode AI configuration with multi-provider support, MCP servers, and custom skills.

![OpenCode](https://img.shields.io/badge/OpenCode-AI%20Coding-blue?style=for-the-badge&logo=ai)
![Models](https://img.shields.io/badge/20+-Models-green?style=for-the-badge)
![Security](https://img.shields.io/badge/Gitleaks-Scanning-red?style=for-the-badge)

---

## âœ¨ Features

### ğŸ” Multi-Provider Authentication

| Provider | Models | Auth |
|----------|--------|------|
| **Google (Antigravity)** | Gemini 3 Pro, Claude 4.5 | OAuth |
| **OpenAI (Codex)** | GPT 5.2 series | OAuth |
| **Z.AI** | GLM-4.7 (Coding Plan) | API Key |
| **Minimax** | Via OpenRouter BYOD | API Key |

### ğŸ¤– Available Models

#### Google (Antigravity + CLI)
```
ğŸ¤– Thinking Models
â”œâ”€â”€ antigravity-gemini-3-pro-low      (1M ctx / 64K out)
â”œâ”€â”€ antigravity-gemini-3-pro-high     (1M ctx / 64K out)
â”œâ”€â”€ antigravity-claude-sonnet-4-5     (200K ctx / 64K out)
â”œâ”€â”€ antigravity-claude-opus-4-5       (200K ctx / 64K out)
â””â”€â”€ Thinking variants (low/medium/high)

âš¡ Fast Models
â”œâ”€â”€ antigravity-gemini-3-flash        (1M ctx / 64K out)
â”œâ”€â”€ gemini-3-pro-preview              (1M ctx / 64K out)
â””â”€â”€ gemini-3-flash-preview            (1M ctx / 64K out)
```

#### OpenAI (Codex OAuth)
```
ğŸ¯ GPT 5.2 Series
â”œâ”€â”€ gpt-5.2-none/medium/high/xhigh    (272K ctx / 128K out)
â”œâ”€â”€ gpt-5.2-codex-low/medium/high     (272K ctx / 128K out)
â””â”€â”€ Reasoning effort: none â†’ xhigh
```

#### Coding Plans (Z.AI + OpenRouter)

| Provider | Plan | Route | Notes |
|----------|------|-------|-------|
| **Z.AI** | GLM-4.7 Coding Plan | Direct API | OpenRouter BYOK charges API cost, not coding plan |
| **OpenRouter** | Minimax BYOK | Via OpenRouter | Uses Minimax coding plan API key |

> **Why Mixed Setup?** We use OpenRouter BYOK to save on provider setup, allowing both Minimax and GLM through one provider. However, Z.AI's OpenRouter BYOK endpoint points to their API billing (not coding plan), so we use Z.AI directly for GLM models and Minimax via OpenRouter BYOK.

### ğŸ”§ MCP Servers

| Server | Type | Purpose |
|--------|------|---------|
| **Context7** | Remote | Documentation search for any library/framework |
| **Chrome DevTools** | Local | Browser automation with Chromium |

### ğŸ§  Skills

| Skill | Purpose |
|-------|---------|
| **github** | GitHub workflow best practices using `gh` CLI |

---

## ğŸ“ Structure

```
~/.config/opencode/
â”œâ”€â”€ opencode.jsonc          # Main configuration
â”œâ”€â”€ AGENTS.md               # Agent instructions
â”œâ”€â”€ skill/
â”‚   â””â”€â”€ github/            # GitHub workflow skill
â”œâ”€â”€ tool/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ gitleaks.yml   # Secret scanning
â””â”€â”€ providers/             # Provider configs
```

---

## ğŸ”’ Security

### Gitleaks Secret Scanning

This repo includes a GitHub Actions workflow that:

- âœ… Scans every push/PR for secrets
- âœ… Detects API keys, tokens, passwords
- âœ… Blocks commits with exposed secrets
- âœ… Creates security issues when found

---

## ğŸš€ Quick Start

### 1. Install OpenCode

```bash
# Using Bun (recommended)
bun install -g opencode

# Or via npm
npm install -g opencode
```

### 2. Clone This Config

```bash
git clone https://github.com/MichaelFisher1997/opencode-config.git ~/.config/opencode
```

### 3. Authenticate

```bash
# Google (Antigravity) - OAuth
opencode auth login

# OpenAI (Codex) - OAuth
opencode auth login

# ZhiPuAI - API Key
export ZHIPUAI_API_KEY="your-key"
```

### 4. Start Coding

```bash
opencode
```

---

## ğŸ’¡ Usage Examples

### Use Specific Models

```bash
# Thinking model for complex tasks
opencode --model google/antigravity-claude-opus-4-5-thinking-high "Design a system"

# Fast model for quick tasks
opencode --model google/antigravity-gemini-3-flash "Fix this typo"

# Codex for coding tasks
opencode --model openai/gpt-5.2-codex-high "Write unit tests"
```

### Browser Automation

```bash
# OpenCode with Chrome DevTools
# MCP server automatically enabled for browser tasks
```

---

## âš™ï¸ Configuration

### Models

Configure models in `opencode.jsonc`:

```jsonc
{
  "model": "zai-coding-plan/glm-4.7",
  "small_model": "zai-coding-plan/glm-4.6v-flash",
  "provider": {
    "google": {
      "models": {
        "antigravity-gemini-3-pro-high": {
          "name": "Gemini 3 Pro High (Antigravity)",
          "thinking": true,
          "attachment": true
        }
      }
    }
  }
}
```

### MCP Servers

```jsonc
{
  "mcp": {
    "context7": {
      "type": "remote",
      "url": "https://mcp.context7.com/mcp"
    }
  }
}
```

---

## ğŸ”§ Troubleshooting

### Authentication Issues

```bash
# Re-authenticate
opencode auth logout
opencode auth login

# Check credentials
opencode auth list
```

### Model Not Found

- Verify model name in `opencode.jsonc`
- Check plugin is loaded: `opencode models`
- Ensure authentication is complete

### MCP Server Issues

```bash
# Check MCP status
opencode mcp list

# Restart MCP servers
opencode mcp restart
```

---

## ğŸ“š Resources

- [OpenCode Docs](https://opencode.ai/docs/)
- [Context7 MCP](https://mcp.context7.com/)
- [Gitleaks](https://github.com/gitleaks/gitleaks)
- [Antigravity Auth](https://github.com/NoeFabris/opencode-antigravity-auth)
- [Codex Auth](https://github.com/numman-ali/opencode-openai-codex-auth)

---

## ğŸ¤ Contributing

This is a personal configuration, but feel free to:

- Fork and adapt for your needs
- Suggest improvements via issues
- Share your own OpenCode configs

---

## ğŸ“ License

This configuration is personal and not licensed for distribution.

OpenCode and related projects have their own licenses.

---

<div align="center">

**Built with â¤ï¸ using OpenCode**

[Star](https://github.com/MichaelFisher1997/opencode-config) â€¢ [Issues](https://github.com/MichaelFisher1997/opencode-config/issues)

</div>
